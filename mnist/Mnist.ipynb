{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from tensorboardX import SummaryWriter\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from PIL import ImageStat\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "learning_rate = 1e-4\n",
    "batch_size = 100\n",
    "model_save_dir = './models'\n",
    "model_name = 'v1_lr_1e-4'\n",
    "log_dir = './runs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.13066048]\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = './data'\n",
    "dataset = torchvision.datasets.MNIST(dataset_dir, train=True, download=True)\n",
    "\n",
    "mean = np.zeros(1)\n",
    "for i in range(len(dataset)):\n",
    "    image = dataset[i][0]\n",
    "    stat = ImageStat.Stat(image)\n",
    "    mean += np.array(stat.mean)\n",
    "    print('\\r{:.2f}%'.format(100*i/len(dataset)), end='\\r')\n",
    "mean /= len(dataset)*255\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_tensor_image(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.13066048 for _ in range(3)])\n",
    "    inp = inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB1CAYAAABeSBpCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAFShJREFUeJzt3XmUVPWVwPHvTUNwRYIsQVBBZVQQ\nCaZHcYgBFSJkEsVJnKCiHI0x8WjcDxE0LlESc1QGnIkyKAY1TIxBEAYXMKhR4wRxBQyixkZFUHEL\nJC6I3vnjvVv1urq6+nVXV71Xj/s5p09VvaXe7R9dP279tieqinPOudr3haQDcM451z68QnfOuYzw\nCt055zLCK3TnnMsIr9Cdcy4jvEJ3zrmM8ArdVZWIqIj8Q0SmJB1LWonIFWEZqYh0SDoeVzu8QndJ\nGKyqFwOIyD+JyAIR2Sgi74nIYhHZtzVvJiLjRGR1WAn+VUQOi3nefSLy98jPFhFZGfPcfxWRx0Tk\nAxF5U0RuEpGdWxGz/cdm177Z9qnqZcDAuO/lnPEK3SWtC7AQ2BfoCTwBLIh7soiMAn4JnALsDHwd\neCXOuao6RlV3sh/gceD3MS+9C3AVsBuwP9AHuCZu3KHBkeuf1spznWtCfKaoqyYRUaC/qr7czP6u\nwLtAN1V9N8b7PQ7MUtVZZcbVF/grsI+qNrTh/H8DrlDVQTGPb6kc+gINQEdV3draeNy2yTN0lzZf\nB96MWZnXAfVAdxF5WUTWich/icj2bbjuycCjbanMQ18Hnm/lOY+EzTXzwgrcubJ4he5SQ0T6AL8C\nzo95Sk+gI/Bd4DDgK8AQ4JI2XP5kYHYbzrNmnwnApa04bTjQF9gPWA8s8g5QVy6v0F0qiEh3YAlw\ng6r+NuZpH4WP/6mqG1T1HWAq8M1WXvtrwJeBua05Lzx3KPA/wHdV9cW456nqI6q6RVU/AM4B+hG0\nxTvXZl6hu8SJyJcIKvOFqhp7OKOqvg+sA8rtCJoAzFPVv7fmJBEZQtChe6qqLi0zBgWkzPdw2ziv\n0F2iRKQzsBj4k6peVGT/iLADsTm/Bn4sIj3C/xjOBRZFzlcRGVHi+tsDx1GkuUVEHhaRy5s57wDg\nfuDHqvq/RfZfLiIPN3PuQBH5iojUichOwHXAG8Dq5uJ0Lg6v0F3SjgX+GTilYEz4HuH+3YH/K3H+\nlcBy4EWCCvEZYArk2uT/DpQaWz4W+BvwUJF9uwN/aua8C4DuwKxIzNFO0VLn9gR+B2wiGGLZF/iW\nqn5aIk7nWuTDFl1VicjHwCfA9ar60xjH3wz8XlUXt+Fa44GBqjqpDef2Ca97aGvPDc9/Fjgyzmid\nIudeRtAx3AnYUVU/a0sMbtvjFbpzzmWEN7k451xGlFWhi8hoEVkTTupo0qHlnHOuetrc5BLO0nsR\nGEUwdGw5cLyq/qX9wnPOORdXOTPTDgZeVtVXAETkDuAYoNkKva6uTjt08MlwzjnXGlu2bHlHVbu3\ndFw5tWtv4PXI63XAIYUHicjpwOkAdXV19O7du4xLOufctqehoeHVOMeV04ZebFZbk/YbVZ2pqvWq\nWl9XV1fG5ZxzzpVSToW+jmDyhOlDsMiQc865BJTT5LIc6C8i/QimLY8DTmjNGzQ0tHWl0trWr1+/\nJtu2xbLwcgh4OQS8HPKKlUUcba7QVXWriJxFsA5HHXCLqrZ2PWjnnHPtpKwhJ6p6L3BvO8XinHOu\nDD6GMOOGDBkCwEMPBWtPrVu3DoAjjjgCgLfffjuZwJxz7c6n/jvnXEZ4hp5xZ599NgCdO3cGYMCA\nAQD07NkT8AzduSzxDN055zJim8vQR4wY0ejxsssua/bYhx9+GIDDDz+8wlG1r8GDB+eeH3vssY32\nvfTSSwC8+26rl+l2zqWcZ+jOOZcR20yGbqM8LDOPw461FSlFauMevueee27uubWdm2effRaA9et9\nUu+2ZMcddwRgv/32A2Dy5MkAjB07Fmj8t716dXBr05/+NLih1Lx586oWZ5rYt9uf/exnAJx11lkA\n/PGPf0wsppZ4hu6ccxnhFbpzzmVEJptcos0q1tTSFtYpau8Xfa80d5R++9vfTjoElwL7779/7vnc\nuXMB2HfffYF8E0uxG9zYMddddx0AjzzyCADvvPNO5YJNoSuvvBKAGTNmAPDcc88lGU4snqE751xG\nZCpDL5ZJt8SycMh3dlx++eWN3q/wMXqMPdaKqVOnJh1Cu9trr70AGDVqFAADBw4E4JRTTskdY52C\nlpk+8cQTACxbtqzJ+910000ArF27FoDNmzdXIOrKqa+vB+Cee+7JbevePbjZjWXkS5YsAWD+/PmN\n9gNcdFFwe+A999wTgPHjxwMwbdq0SoadqC98IZ/bTpw4Ecj/vjfffHMiMbWFZ+jOOZcRmczQ47ji\niiuA0hm2Ze92bKlJSLXigw8+SDqEdjN06FAAli5dCsB2223X7LGWmdqjZbH2GHXmmWcCsGLFCgDe\neustAKZPn5475r777isr9kqwNnPLzHfdddfcPvu9p0yZAsCll17a7PtYG/qJJ54I5DP2LGboPXr0\nAOD666/PbbNveMOGDUskpnJ4hu6ccxmRqQzdMupoJm3bCtvHW8POSXuGftJJJwGwyy67JBxJdVgG\nWiozL2SZ6tatW1s8dtCgQQAceOCBQH7JYcgvQ7xq1SoAvvOd7wDw6aefxo6lvd12221Avj1848aN\nuX1nnHEGEG+S0GOPPQbk287t/Yq9b62zb2PHHXdcbpuV1aZNmxKJqRyeoTvnXEZkMkOvlSn67e2Q\nQw4BoK6ursk+a/N99dVXqxpTJVlbsY2XvuCCCxrtX7NmTe75hg0bAPjFL34BwB/+8IcW33/kyJEA\nzJo1C4A+ffrk9tkIEHu0cd7HHHNMK3+L9mMjVvbYYw8AxowZk9v39NNPx34fy+JvvPFGIP+txr4B\nRN+31g0fPhxoPMZ+5syZSYVTNs/QnXMuI7xCd865jMhUk8u2bsKECc3us/XPP/7442qFUzU2rK5w\nKOHjjz+ee/7JJ5+0+n2tWcbKLtrkUuiAAw5o9fu3t5///OeNHtvKmh/s7+nWW28F4KijjgLgoIMO\nyh3bmqacNOnXrx+Q7/C+8847kwyn3XiG7pxzGeEZegxpn95//PHHA7D99ts32Wf3DLUFhspha2kD\n/PCHPwTy0+4tKyw2lb7SPv/8c6C8hdiirFPd1r+2iSal2LFZYuuiF1vAq9bZcEUb4msTrmqdZ+jO\nOZcRnqGXUHjfUVsCANKVtdswtegCQ2bRokVA4/bkuGxBK8tevve97+X29ezZs9Gxo0ePBuD+++8H\n4Ec/+lFunw0ZrBUDBgwA4k11t/b1Bx54oKIxJeG1114D4PXXXwfyQzSzwCaj/fnPfwby32RrnWfo\nzjmXEZ6hl5D2qf6VYhmqTSw57LDDmj3W2ps7duwI5G+uYdPHAa655pqKxFkpl1xySYvHWEZ39NFH\nA/GWEqg1NsXfRr3YN0G71ybU7igX06lTJ6D4t9talI3fwjnnnGfoxRTe4KJwe1ZZm7lNobfM3MZw\nP/nkk7ljbbnRnXfeGYBrr70WgC5dugAwbty43LG1kKHbeGSIN31/9uzZACxfvrxSIaWOfRvr1q1b\nwpGU7/333wfyY+rt2wc0XjKi1niG7pxzGeEVunPOZUQmmlyK3fOzJaWaTwo7Q6PDFdPImjnaYocd\ndsg9t2YUuxfnli1bgHwnoa1qGGUTi6zjzGLZbbfd2hxTEr7xjW/knltHWaEXXngh9/yGG26oeExJ\nszsg2YQym2AULYdadccddwAwefJkoHETYdo/76V4hu6ccxlRkxm6ZeLlTPXO0pDE888/v9XnDBky\nBICrr746t23UqFFAPjO37GXq1KlNzrfM3BbE2meffRrtL3ZOGtmdhkrdY9PYeuCQn2yTZTZZzL7F\nWafoo48+mlhM7cU6Ph988EEALrzwwty+vffeG4BXXnml0TnWWW6T5wDuuusuoPGAgSR5hu6ccxnR\nYoYuIrsDtwFfBj4HZqrqdBHpCvwO6AusBf5dVd+vXKh57bUIU1yWzdsdkQqfJ+3DDz8E4t1L1NqH\nzznnHCCflUfZ/Vcty+7cuTMAvXv3zh2zYMECAPr37w/kF8iyaf5pnwpvE0lsOQMbsllKLd/JpjWs\n7dyWJS5sO89CG7pNBDv11FMBuOWWW3L77NvrwQcfDMD69esB6NAhqC4nTpyYO9b6m+rr64H8vWaT\nEidD3wpcoKr7A0OBM0VkAHARsFRV+wNLw9fOOecS0mKGrqobgA3h880ishroDRwDjAgPuxV4GPhJ\nRaKk9BKehb3SpUawlNP+Hj3HMnTLZpOcdGTt4Ha/zKihQ4cC0KtXLyC/zO3JJ5/c5NiGhgYAzjvv\nPCCfqdkCX3ZTgKiPPvoIgDlz5gDwgx/8oI2/RXXZyA1rQy9l0qRJAGzevLmiMVVD9+7dgcYTaaLb\nIf/72jb77J1xxhlA/hthFlhfSPQ+qdZnYBn5e++9B+S/qdrnBPJlZPuS1qpOURHpCwwBlgE9w8oe\nVd0gIj2aOed04HQofvNi55xz7SN2p6iI7ATcBZyrqpvinqeqM1W1XlXrvUJ3zrnKiZWhi0hHgsp8\njqrOCze/JSK9wuy8F1CRBYVLNWVYU0uc5g5rLimcfBTt3LTmEzN8+PCi50S32aO9TxKdpZ999lmz\n+2zlROuktKaXYqxJZdWqVS1e01biGzlyJAArV66MF2xKxFlR0SxZsgSovRUVrckM8kMubR0Wa3Kx\n5hQbkhjdVvho9xaNNk9koYMUGv/bbtpUPF894YQTAOjatWtum62n/uabb1YwuvhazNAl+JeeBaxW\n1ejg4oWA3ZV4ArCg/cNzzjkXV5wMfRhwErBSRJ4Nt00GrgbuFJHvA68Bx1UmxOZZBl2Yodt2aHk5\ngGiHakvZdfQ6pbL3arOVDocNGwYUXy3QMvVy2PR+gCOPPBKIl82nyeDBg4H8Oual2FIHK1asqGhM\n7c2G0N1zzz25bYUdnNGMvNjrYtvsjkXPP/98btuECUFON29e8MU9Sx2mxr6F2oACGwgA+QEE1nGa\ntDijXB4Dmv5rB45s33Ccc861lVTzjt6dOnXS6OSU6PCf5rTHNP9iDj/8cKD8Nu/CNvQ4ig3/i1MW\nWVPNcrB122+//XYgf2elYqwNddCgQUDlJ4u0dznMmDEDgNNOOy23zbLtwgx99erVAMyfPz93bPQ5\n5NvirR0+WmfY+9g51t9gWjMZK62fi8JvHdaWDnD33XdX5JqFZdHQ0PCUqta3dJ5P/XfOuYxI/eJc\nlvlG27pbWlir1MiV9p4AlKYlAFzzxo4dC5TOzM1TTz0FJD+Nu61ssswzzzzTZJ9l5JZZWtt3KXbf\nUHvf6DLKX/3qV4H8fUZtopYtBRFdyMuuXSusNcEmzc2aNQvIj2xJI8/QnXMuI1Lfhp5FaW0rrLZK\nl0P0RhV278+BAwcWPdaycsiPYIqOZqikWvt7iN5TdPz48UB+Ia/C0TQ2fT6OtJSD1VG28JbdzKSa\nI1m8Dd0557ZxXqE751xGpL5T1Lm2ii6JYOu0N9fksnjx4tzzajW11KroBLNp06Y1esyCN954A4Cr\nrroq4UhazzN055zLCM/QXWZFF1y69957gfw0bvOb3/wGgClTplQvMOcqxDN055zLCM/Q3TZh+vTp\njR6dyyLP0J1zLiO8QnfOuYzwCt055zLCK3TnnMuIRNdycc451zJfy8U557YxXqE751xGeIXunHMZ\nUdU2dBHZCPwDeKelY1OkGx5vJXm8leXxVla14t1TVbu3dFBVK3QAEXkyTuN+Wni8leXxVpbHW1lp\ni9ebXJxzLiO8QnfOuYxIokKfmcA1y+HxVpbHW1keb2WlKt6qt6E755yrDG9ycc65jPAK3TnnMqJq\nFbqIjBaRNSLysohcVK3rxiUiu4vIQyKyWkSeF5Fzwu1dReQBEXkpfPxS0rFGiUidiDwjIovC1/1E\nZFkY7+9E5ItJxxglIl1EZK6IvBCW9aFpLmMROS/8e1glIr8Vke3SVMYicouIvC0iqyLbipanBK4P\nP4MrROSglMR7Tfj3sEJE5otIl8i+SWG8a0TkqDTEG9l3oYioiHQLXydevlWp0EWkDvgVMAYYABwv\nIgOqce1W2ApcoKr7A0OBM8MYLwKWqmp/YGn4Ok3OAVZHXv8S+I8w3veB7ycSVfOmA/er6n7AYILY\nU1nGItIbOBuoV9UDgDpgHOkq49nA6IJtzZXnGKB/+HM6cGOVYoyaTdN4HwAOUNUDgReBSQDh528c\nMDA854awLqmm2TSNFxHZHRgFvBbZnHz5qmrFf4BDgcWR15OASdW4dhkxLyD4B1sD9Aq39QLWJB1b\nJMY+BB/YI4BFgBDMWutQrNyT/gE6Aw2EnfGR7aksY6A38DrQleB2jYuAo9JWxkBfYFVL5Qn8N3B8\nseOSjLdg37HAnPB5o3oCWAwcmoZ4gbkECclaoFtayrdaTS72wTDrwm2pJCJ9gSHAMqCnqm4ACB97\nJBdZE9OAicDn4etdgQ9U1W53n7Zy3gvYCPw6bCa6WUR2JKVlrKpvANcSZGEbgL8BT5HuMobmy7MW\nPoenAveFz1MZr4gcDbyhqs8V7Eo83mpV6FJkWyrHS4rITsBdwLmquinpeJojIt8C3lbVp6Kbixya\npnLuABwE3KiqQwjW9UlF80oxYdvzMUA/YDdgR4Kv1YXSVMalpPrvQ0QuJmj6nGObihyWaLwisgNw\nMXBpsd1FtlU13mpV6OuA3SOv+wDrq3Tt2ESkI0FlPkdV54Wb3xKRXuH+XsDbScVXYBhwtIisBe4g\naHaZBnQRkQ7hMWkr53XAOlVdFr6eS1DBp7WMRwINqrpRVT8F5gH/QrrLGJovz9R+DkVkAvAt4EQN\n2ytIZ7x7E/wH/1z42esDPC0iXyYF8VarQl8O9A9HB3yRoKNjYZWuHYuICDALWK2qUyO7FgITwucT\nCNrWE6eqk1S1j6r2JSjPB1X1ROAh4LvhYamJF0BV3wReF5F9w01HAn8hpWVM0NQyVER2CP8+LN7U\nlnGoufJcCJwcjsYYCvzNmmaSJCKjgZ8AR6vqh5FdC4FxItJJRPoRdDY+kUSMRlVXqmoPVe0bfvbW\nAQeFf9vJl28VOxa+SdCD/Vfg4mp3bMSI72sEX49WAM+GP98kaJdeCrwUPnZNOtYisY8AFoXP9yL4\no38Z+D3QKen4CmL9CvBkWM53A19KcxkDVwAvAKuA24FOaSpj4LcE7fufElQu32+uPAmaBH4VfgZX\nEozeSUO8LxO0Pdvnbkbk+IvDeNcAY9IQb8H+teQ7RRMvX5/675xzGeEzRZ1zLiO8QnfOuYzwCt05\n5zLCK3TnnMsIr9Cdcy4jvEJ3zrmM8ArdOecy4v8BpTRUd4QY+J0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efea873c780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trans = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, [1., 1., 1.])\n",
    "])\n",
    "dataset = torchvision.datasets.MNIST('./data', train=True, download=True, transform=trans)\n",
    "dataloader = DataLoader(dataset, batch_size=5, shuffle=True, num_workers=1)\n",
    "images, labels = next(iter(dataloader))\n",
    "show_tensor_image(torchvision.utils.make_grid(images), title=[x.item() for x in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 60000, 'test': 10000}\n"
     ]
    }
   ],
   "source": [
    "trans = {}\n",
    "trans['train'] = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, [1., 1., 1.])\n",
    "])\n",
    "trans['test'] = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, [1., 1., 1.])\n",
    "])\n",
    "datasets = {\n",
    "    'train': torchvision.datasets.MNIST(dataset_dir, train=True, download=True, transform=trans['train']),\n",
    "    'test': torchvision.datasets.MNIST(dataset_dir, train=False, download=True, transform=trans['test'])\n",
    "}\n",
    "dataloaders = {x: DataLoader(datasets[x], batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "                for x in ['train', 'test']}\n",
    "dataset_sizes = {x: len(datasets[x]) for x in ['train', 'test']}\n",
    "print(dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "tensor([[[-0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307],\n",
      "         [-0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307],\n",
      "         [-0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307],\n",
      "         [-0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307],\n",
      "         [-0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307,  0.3438,  0.8615,  0.3988,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307],\n",
      "         [-0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307,  0.0576,  0.7674,  0.8576,  0.8340,\n",
      "           0.2537, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307],\n",
      "         [-0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307,  0.0223,  0.7360,  0.8576,  0.8576,  0.8497,\n",
      "           0.3046, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307],\n",
      "         [-0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307,  0.1046,  0.8576,  0.8576,  0.8576,  0.4615,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307],\n",
      "         [-0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307,  0.1674,  0.6693,  0.8576,  0.8576,  0.7674,  0.0733,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307],\n",
      "         [-0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307,  0.8615,  0.8576,  0.8576,  0.8576,  0.4929, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307],\n",
      "         [-0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307,  0.8615,  0.8576,  0.8576,  0.8576, -0.0169, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307],\n",
      "         [-0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "           0.4223,  0.8615,  0.8576,  0.8576,  0.4144, -0.1228, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307],\n",
      "         [-0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,  0.1086,\n",
      "           0.7635,  0.8615,  0.8576,  0.8105, -0.0091, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307],\n",
      "         [-0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,  0.6262,\n",
      "           0.8576,  0.8615,  0.8576,  0.4497, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307],\n",
      "         [-0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,  0.0184,  0.7282,\n",
      "           0.8615,  0.8693,  0.7635,  0.0772, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307],\n",
      "         [-0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.0052,  0.7164,  0.8576,\n",
      "           0.8576,  0.8615,  0.4850, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307],\n",
      "         [-0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307,  0.3948,  0.8576,  0.8576,\n",
      "           0.8576,  0.8380,  0.0301, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307],\n",
      "         [-0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.0718,  0.6105,  0.8576,  0.8576,\n",
      "           0.8576,  0.1791, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307],\n",
      "         [-0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.0405,  0.5870,  0.8576,  0.8576,  0.8576,\n",
      "           0.6811, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307],\n",
      "         [-0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307,  0.1635,  0.8576,  0.8576,  0.8576,  0.8340,\n",
      "           0.2262, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307],\n",
      "         [-0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307,  0.4693,  0.8576,  0.8576,  0.8576,  0.3713,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307],\n",
      "         [-0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1071,  0.4968,  0.8497,  0.8576,  0.8576,  0.8576,  0.1007,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307],\n",
      "         [-0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.0718,  0.8576,  0.8576,  0.8576,  0.8576,  0.4811, -0.0758,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307],\n",
      "         [-0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.0718,  0.8576,  0.8576,  0.8576,  0.8576, -0.0758, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307],\n",
      "         [-0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307],\n",
      "         [-0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307],\n",
      "         [-0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307],\n",
      "         [-0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307,\n",
      "          -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307, -0.1307]]])\n",
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(dataloaders['train']))\n",
    "print(images.size())\n",
    "print(labels.size())\n",
    "print(images[0])\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            #28x28\n",
    "            nn.Conv2d(1, 32, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            #14x14\n",
    "            nn.Conv2d(32, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            #7x7\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64 * 7 * 7, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "        \n",
    "        self._initialize_weights()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "writer = {x: SummaryWriter(log_dir=os.path.join(log_dir, model_name, x),\n",
    "                comment=model_name)\n",
    "          for x in ['train', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(device)\n",
    "criterion = nn.CrossEntropyLoss(size_average=False)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0)\n",
    "#scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[20,30], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training():\n",
    "    since = time.time()\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_accuracy = 0.0\n",
    "    iter_num = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        #scheduler.step()\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'test']:\n",
    "            if phase == 'train':\n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            # Iterate over data.\n",
    "            for idx, data in enumerate(dataloaders[phase]):\n",
    "                # get the inputs\n",
    "                inputs, labels = data\n",
    "\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                if phase == 'train':\n",
    "                    torch.set_grad_enabled(True)\n",
    "                else:\n",
    "                    torch.set_grad_enabled(False)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    iter_num += 1\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item()\n",
    "                _, preds = torch.max(outputs.detach(), 1)\n",
    "                running_corrects += torch.sum(preds == labels.detach()).item()\n",
    "\n",
    "                if idx%10 == 0:\n",
    "                    if phase == 'train':\n",
    "                        preds = preds.to('cpu')\n",
    "                        labels = labels.detach().to('cpu')\n",
    "                        writer[phase].add_scalar('loss', loss.item()/len(preds), iter_num)\n",
    "                        writer[phase].add_scalar('accuracy', accuracy_score(preds.numpy(), labels.numpy()), iter_num)\n",
    "                    print('\\r{} {:.2f}%'.format(phase, 100*idx/len(dataloaders[phase])), end='\\r')\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_accuracy = running_corrects / dataset_sizes[phase]\n",
    "\n",
    "            if phase == 'test':\n",
    "                writer[phase].add_scalar('loss', epoch_loss, iter_num)\n",
    "                writer[phase].add_scalar('accuracy', epoch_accuracy, iter_num)\n",
    "            print('{} Loss: {:.4f} Accuracy: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_accuracy))\n",
    "\n",
    "            # save model\n",
    "            if phase == 'test' and epoch_accuracy > best_accuracy:\n",
    "                best_accuracy = epoch_accuracy\n",
    "                best_model_wts = model.state_dict()\n",
    "                model_dir = os.path.join(model_save_dir, model_name+'.pth')\n",
    "                if not os.path.exists(model_save_dir):\n",
    "                    os.makedirs(model_save_dir)\n",
    "                torch.save(model.state_dict(), model_dir)\n",
    "                print('Model saved to %s'%(model_dir))\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best Test Accuracy: {:4f}'.format(best_accuracy))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n",
      "train Loss: 0.3700 Accuracy: 0.8798\n",
      "test Loss: 0.0597 Accuracy: 0.9793\n",
      "Model saved to ./models/v1_lr_1e-4.pth\n",
      "\n",
      "Epoch 1/4\n",
      "----------\n",
      "train Loss: 0.0762 Accuracy: 0.9777\n",
      "test Loss: 0.0332 Accuracy: 0.9889\n",
      "Model saved to ./models/v1_lr_1e-4.pth\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "train Loss: 0.0588 Accuracy: 0.9818\n",
      "test Loss: 0.0346 Accuracy: 0.9895\n",
      "Model saved to ./models/v1_lr_1e-4.pth\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "train Loss: 0.0467 Accuracy: 0.9861\n",
      "test Loss: 0.0254 Accuracy: 0.9907\n",
      "Model saved to ./models/v1_lr_1e-4.pth\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "train Loss: 0.0415 Accuracy: 0.9875\n",
      "test Loss: 0.0319 Accuracy: 0.9905\n",
      "\n",
      "Training complete in 0m 38s\n",
      "Best Test Accuracy: 0.990700\n"
     ]
    }
   ],
   "source": [
    "training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
